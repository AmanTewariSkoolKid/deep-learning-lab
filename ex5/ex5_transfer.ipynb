{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d995049e",
   "metadata": {},
   "source": [
    "# Transfer Learning on Flower Photos (Keras)\n",
    "\n",
    "This notebook mirrors train_transfer.py with clear steps:\n",
    "- Load config\n",
    "- Build datasets with augmentation\n",
    "- Build transfer model head\n",
    "- Train (feature extraction) and optionally fine-tune\n",
    "- Evaluate and optionally export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5da7a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.20.0\n",
      "NumPy: 1.26.4\n",
      "Has _ARRAY_API: True\n",
      "ml_dtypes: 0.5.3\n",
      "Loaded config for task: image_classification_transfer_learning\n"
     ]
    }
   ],
   "source": [
    "# Imports, environment checks, and config loading\n",
    "import os, json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "print('TensorFlow:', tf.__version__)\n",
    "print('NumPy:', np.__version__)\n",
    "# Check for _ARRAY_API presence\n",
    "has_array_api = hasattr(np.core.multiarray, '_ARRAY_API') if hasattr(np, 'core') and hasattr(np.core, 'multiarray') else False\n",
    "print('Has _ARRAY_API:', has_array_api)\n",
    "try:\n",
    "    import ml_dtypes\n",
    "    print('ml_dtypes:', getattr(ml_dtypes, '__version__', 'unknown'))\n",
    "except Exception as e:\n",
    "    print('ml_dtypes import error:', e)\n",
    "\n",
    "# Load config\n",
    "with open('config_transfer.json', 'r', encoding='utf-8') as f:\n",
    "    cfg = json.load(f)\n",
    "print('Loaded config for task:', cfg['task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e4f522e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 files belonging to 0 classes.\n",
      "Using 0 files for training.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No images found in directory data/flowers/. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m     AUTOTUNE = tf.data.AUTOTUNE\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m train_ds.prefetch(AUTOTUNE), val_ds.prefetch(AUTOTUNE), class_names\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m train_ds, val_ds, class_names = \u001b[43mbuild_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mClasses:\u001b[39m\u001b[33m'\u001b[39m, class_names)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mbuild_datasets\u001b[39m\u001b[34m(cfg)\u001b[39m\n\u001b[32m      4\u001b[39m ds_cfg = cfg[\u001b[33m'\u001b[39m\u001b[33mdataset\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m img_size = \u001b[38;5;28mtuple\u001b[39m(ds_cfg[\u001b[33m'\u001b[39m\u001b[33mimage_size\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m train_ds = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreprocessing\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimage_dataset_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mds_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpath\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mvalidation_split\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtraining\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtraining\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbatch_size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mds_cfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclass_mode\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m val_ds = keras.preprocessing.image_dataset_from_directory(\n\u001b[32m     10\u001b[39m     ds_cfg[\u001b[33m'\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m'\u001b[39m], validation_split=ds_cfg[\u001b[33m'\u001b[39m\u001b[33mvalidation_split\u001b[39m\u001b[33m'\u001b[39m], subset=\u001b[33m'\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     11\u001b[39m     seed=ds_cfg[\u001b[33m'\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m'\u001b[39m], image_size=img_size, batch_size=cfg[\u001b[33m'\u001b[39m\u001b[33mtraining\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mbatch_size\u001b[39m\u001b[33m'\u001b[39m], label_mode=ds_cfg[\u001b[33m'\u001b[39m\u001b[33mclass_mode\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     12\u001b[39m class_names = train_ds.class_names\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\image_dataset_utils.py:329\u001b[39m, in \u001b[36mimage_dataset_from_directory\u001b[39m\u001b[34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, pad_to_aspect_ratio, data_format, verbose)\u001b[39m\n\u001b[32m    325\u001b[39m image_paths, labels = dataset_utils.get_training_or_validation_split(\n\u001b[32m    326\u001b[39m     image_paths, labels, validation_split, subset\n\u001b[32m    327\u001b[39m )\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image_paths:\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    330\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo images found in directory \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    331\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAllowed formats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mALLOWLIST_FORMATS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    332\u001b[39m     )\n\u001b[32m    334\u001b[39m dataset = paths_and_labels_to_dataset(\n\u001b[32m    335\u001b[39m     image_paths=image_paths,\n\u001b[32m    336\u001b[39m     image_size=image_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    347\u001b[39m     seed=seed,\n\u001b[32m    348\u001b[39m )\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: No images found in directory data/flowers/. Allowed formats: ('.bmp', '.gif', '.jpeg', '.jpg', '.png')"
     ]
    }
   ],
   "source": [
    "# Dataset builder\n",
    "\n",
    "def build_datasets(cfg):\n",
    "    ds_cfg = cfg['dataset']\n",
    "    img_size = tuple(ds_cfg['image_size'])\n",
    "    train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "        ds_cfg['path'], validation_split=ds_cfg['validation_split'], subset='training',\n",
    "        seed=ds_cfg['seed'], image_size=img_size, batch_size=cfg['training']['batch_size'], label_mode=ds_cfg['class_mode'])\n",
    "    val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "        ds_cfg['path'], validation_split=ds_cfg['validation_split'], subset='validation',\n",
    "        seed=ds_cfg['seed'], image_size=img_size, batch_size=cfg['training']['batch_size'], label_mode=ds_cfg['class_mode'])\n",
    "    class_names = train_ds.class_names\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    return train_ds.prefetch(AUTOTUNE), val_ds.prefetch(AUTOTUNE), class_names\n",
    "\n",
    "train_ds, val_ds, class_names = build_datasets(cfg)\n",
    "print('Classes:', class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22902ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation and model builder\n",
    "\n",
    "def build_augmentation(cfg):\n",
    "    aug_cfg = cfg['augmentation']\n",
    "    if not aug_cfg.get('enabled', False):\n",
    "        return keras.Sequential(name='no_aug')\n",
    "    layers_list = []\n",
    "    if aug_cfg.get('horizontal_flip'): layers_list.append(layers.RandomFlip('horizontal'))\n",
    "    if aug_cfg.get('rotation_range'): layers_list.append(layers.RandomRotation(aug_cfg['rotation_range']/360.0))\n",
    "    if aug_cfg.get('zoom_range'): layers_list.append(layers.RandomZoom(aug_cfg['zoom_range']))\n",
    "    if aug_cfg.get('width_shift_range') or aug_cfg.get('height_shift_range'):\n",
    "        layers_list.append(layers.RandomTranslation(\n",
    "            height_factor=aug_cfg.get('height_shift_range', 0),\n",
    "            width_factor=aug_cfg.get('width_shift_range', 0)))\n",
    "    return keras.Sequential(layers_list, name='augmentation')\n",
    "\n",
    "\n",
    "def build_model(cfg, num_classes):\n",
    "    model_cfg = cfg['model']; head_cfg = cfg['head']\n",
    "    base = getattr(keras.applications, model_cfg['base_architecture'])(\n",
    "        include_top=model_cfg['include_top'], weights=model_cfg['weights'],\n",
    "        input_shape=(*cfg['dataset']['image_size'], 3)\n",
    "    )\n",
    "    base.trainable = False if model_cfg['trainable_strategy'] in ('freeze_then_finetune','freeze') else True\n",
    "\n",
    "    inputs = keras.Input(shape=(*cfg['dataset']['image_size'], 3))\n",
    "    x = build_augmentation(cfg)(inputs)\n",
    "    prep_fn = getattr(keras.applications, model_cfg['base_architecture']).preprocess_input\n",
    "    x = layers.Lambda(prep_fn)(x)\n",
    "    x = base(x, training=False)\n",
    "\n",
    "    if head_cfg['global_pool'] == 'avg': x = layers.GlobalAveragePooling2D()(x)\n",
    "    elif head_cfg['global_pool'] == 'max': x = layers.GlobalMaxPooling2D()(x)\n",
    "    else: x = layers.Flatten()(x)\n",
    "\n",
    "    for units in head_cfg['dense_units']:\n",
    "        x = layers.Dense(units, activation=head_cfg['activation'])(x)\n",
    "        if head_cfg.get('dropout', 0) > 0:\n",
    "            x = layers.Dropout(head_cfg['dropout'])(x)\n",
    "    outputs = layers.Dense(head_cfg['output_classes'], activation=head_cfg['output_activation'])(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model, base\n",
    "\n",
    "model, base = build_model(cfg, len(class_names))\n",
    "model.summary(line_length=120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3523af54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and feature extraction training\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def compile_model(model, lr, optimizer_name):\n",
    "    if optimizer_name == 'adam':\n",
    "        opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        opt = keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError('Unsupported optimizer')\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "tr_cfg = cfg['training']\n",
    "compile_model(model, tr_cfg['learning_rates']['feature_extraction'], tr_cfg['optimizer'])\n",
    "\n",
    "callbacks = []\n",
    "if tr_cfg.get('early_stopping'):\n",
    "    es = tr_cfg['early_stopping']\n",
    "    callbacks.append(keras.callbacks.EarlyStopping(monitor=es['monitor'], patience=es['patience'], restore_best_weights=True))\n",
    "if tr_cfg.get('checkpoint'):\n",
    "    ck = tr_cfg['checkpoint']\n",
    "    Path('checkpoints').mkdir(exist_ok=True)\n",
    "    callbacks.append(keras.callbacks.ModelCheckpoint('checkpoints/best.keras', monitor=ck['monitor'], save_best_only=ck['save_best_only']))\n",
    "\n",
    "history_fe = model.fit(train_ds, validation_data=val_ds, epochs=tr_cfg['feature_extraction_epochs'], callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e19ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning phase (optional)\n",
    "\n",
    "ft_cfg = tr_cfg.get('fine_tune', {\"enabled\": False})\n",
    "if ft_cfg.get('enabled', False):\n",
    "    # Find the base model by name or type\n",
    "    base_layer_name = 'base_model'\n",
    "    try:\n",
    "        base_model = model.get_layer(base_layer_name)\n",
    "    except ValueError:\n",
    "        # fallback: first layer with trainable set to False typically is the base\n",
    "        base_model = None\n",
    "        for layer in model.layers:\n",
    "            if hasattr(layer, 'layers') and any(getattr(l, 'trainable', True) is False for l in layer.layers):\n",
    "                base_model = layer\n",
    "                break\n",
    "        if base_model is None:\n",
    "            # last resort: treat the first layer as base\n",
    "            base_model = model.layers[0]\n",
    "    unfreeze_from = ft_cfg.get('unfreeze_from', 0)\n",
    "    for i, layer in enumerate(base_model.layers):\n",
    "        layer.trainable = (i >= unfreeze_from)\n",
    "    print(f\"Unfroze layers from index {unfreeze_from} (total {len(base_model.layers)})\")\n",
    "\n",
    "    compile_model(model, tr_cfg['learning_rates']['fine_tuning'], tr_cfg['optimizer'])\n",
    "    history_ft = model.fit(train_ds, validation_data=val_ds, epochs=ft_cfg.get('epochs', 5), callbacks=callbacks)\n",
    "else:\n",
    "    history_ft = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation and reporting\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "val_batches = list(val_ds)\n",
    "X_val = np.concatenate([x.numpy() for x, _ in val_batches], axis=0)\n",
    "y_val = np.concatenate([y.numpy() for _, y in val_batches], axis=0)\n",
    "\n",
    "pred_probs = model.predict(X_val, batch_size=32)\n",
    "pred_labels = pred_probs.argmax(axis=1)\n",
    "true_labels = y_val.argmax(axis=1)\n",
    "\n",
    "print('Classification Report:')\n",
    "print(classification_report(true_labels, pred_labels, target_names=class_names))\n",
    "\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(true_labels, pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044b62b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "histories = [h for h in [history_fe, history_ft] if h is not None]\n",
    "history = {}\n",
    "for h in histories:\n",
    "    for k, v in h.history.items():\n",
    "        history.setdefault(k, []).extend(v)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.get('loss', []), label='train')\n",
    "plt.plot(history.get('val_loss', []), label='val')\n",
    "plt.title('Loss'); plt.legend(); plt.grid(True)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.get('accuracy', []), label='train')\n",
    "plt.plot(history.get('val_accuracy', []), label='val')\n",
    "plt.title('Accuracy'); plt.legend(); plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
